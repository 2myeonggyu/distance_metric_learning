{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# readme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### # contrastive loss를 사용할 때 주의점\n",
    "- distance 를 기준으로, 거리가 가까우면 '같다'고 정의. 따라서, accuracy를 측정할때 살펴보면 아래와 같이 정의되어 있다는점에 주의하자!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.'''\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2],\n",
       "        [3, 4]],\n",
       "\n",
       "       [[5, 6],\n",
       "        [7, 8]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,2,3,4],\n",
    "         [5,6,7,8]]).reshape(2,2,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../train_within_0_35_balanced/X_tain.pkl', 'rb') as f:\n",
    "    X_train = pickle.load( f )\n",
    "    \n",
    "with open('../train_within_0_35_balanced/y_train.pkl', 'rb') as f:\n",
    "    y_train = pickle.load( f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(330519, 512) (330519,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test_data : TEST_within_035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../test_data(common)/TEST_within_035/test_pair_035.pkl',\n",
       " '../test_data(common)/TEST_within_035/test_pair_v2_035.pkl',\n",
       " '../test_data(common)/TEST_within_035/test_label_035.pkl',\n",
       " '../test_data(common)/TEST_within_035/ReadME.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('../test_data(common)/TEST_within_035/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../test_data(common)/TEST_within_035/test_pair_v2_035.pkl', 'rb') as f:\n",
    "    X_test_dict = pickle.load( f )\n",
    "    \n",
    "with open('../test_data(common)/TEST_within_035/test_label_035.pkl', 'rb') as f:\n",
    "    y_test_dict = pickle.load( f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data 100개 array로\n",
    "\n",
    "X_test = np.array([])\n",
    "y_test = np.array([])\n",
    "\n",
    "for i,key in enumerate(X_test_dict.keys()):\n",
    "    if i == 0:\n",
    "        X_test = X_test_dict[key]\n",
    "        y_test = y_test_dict[key]\n",
    "    else:\n",
    "        X_test = np.append( X_test, X_test_dict[key], axis=0 )\n",
    "        y_test = np.append( y_test, y_test_dict[key], axis=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2183, 512) (2183,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pair 데이터로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330519, 512)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_pairs = X_train.reshape(len(X_train), 2, 16 , 16)\n",
    "tr_y = np.array(y_train, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(330519, 2, 16, 16) (330519,)\n"
     ]
    }
   ],
   "source": [
    "print(tr_pairs.shape, tr_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_pairs[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_pairs[0][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16*16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1, 2],\n",
       "         [3, 4]],\n",
       "\n",
       "        [[5, 6],\n",
       "         [7, 8]]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3,4,5,6,7,8]).reshape(1,2,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_pairs = X_test.reshape(len(X_test), 2, 16, 16)\n",
    "te_y  = np.array(y_test, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2183, 2, 16, 16) (2183,)\n"
     ]
    }
   ],
   "source": [
    "print(te_pairs.shape, te_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.42188190e-01, 7.30437040e-02, 6.54419840e-03, 3.47212740e-02,\n",
       "         5.42317420e-03, 1.90891240e-01, 5.48556100e-02, 1.90691950e-02,\n",
       "         5.31537460e-02, 0.00000000e+00, 5.68175540e-02, 5.99295230e-03,\n",
       "         1.46555270e-02, 4.06781440e-02, 1.76598880e-02, 1.24414280e-02],\n",
       "        [1.28487740e-02, 4.53592050e-02, 1.00350100e-01, 1.98895630e-02,\n",
       "         9.20542700e-02, 3.93058300e-02, 1.24327300e-01, 3.21867800e-03,\n",
       "         8.68949800e-02, 1.43282760e-02, 9.36443100e-02, 1.18206380e-01,\n",
       "         1.22040810e-02, 2.52782850e-02, 9.00668600e-03, 0.00000000e+00],\n",
       "        [8.05807200e-03, 9.45651700e-03, 8.39080550e-04, 0.00000000e+00,\n",
       "         3.74782390e-03, 3.84895430e-02, 1.26211840e-01, 6.53332500e-02,\n",
       "         1.48222810e-02, 2.08259040e-02, 1.86327680e-02, 6.20653000e-02,\n",
       "         6.73222240e-02, 3.96289630e-03, 6.58821500e-02, 7.18304900e-02],\n",
       "        [4.85406550e-04, 1.54494160e-02, 3.96003300e-02, 1.80409630e-02,\n",
       "         1.19384915e-01, 0.00000000e+00, 1.36813470e-02, 1.47173190e-02,\n",
       "         2.92952450e-02, 2.13649430e-03, 1.32019470e-03, 3.90524100e-02,\n",
       "         8.63014100e-02, 4.61369300e-04, 4.92780360e-02, 6.25189700e-02],\n",
       "        [1.67946710e-01, 5.87217700e-02, 1.69698670e-02, 0.00000000e+00,\n",
       "         1.05985420e-02, 6.11168200e-03, 2.00512390e-02, 9.96611940e-02,\n",
       "         7.71087800e-02, 1.21918480e-01, 6.34290100e-04, 1.58467110e-01,\n",
       "         4.80080100e-02, 0.00000000e+00, 1.26646920e-02, 4.37583920e-02],\n",
       "        [1.11521060e-02, 1.56929960e-02, 3.22057530e-02, 1.78935100e-02,\n",
       "         2.71946120e-02, 1.14694160e-03, 1.09654190e-02, 9.68023800e-02,\n",
       "         1.59835710e-01, 1.48182910e-01, 7.81928200e-02, 3.84040900e-02,\n",
       "         6.61666700e-02, 1.97963730e-02, 1.12522200e-01, 5.88867600e-02],\n",
       "        [1.78719700e-02, 8.13974500e-02, 1.24341350e-03, 0.00000000e+00,\n",
       "         0.00000000e+00, 6.48901500e-03, 1.45392400e-02, 1.20278600e-02,\n",
       "         7.91529900e-02, 2.46456600e-02, 1.00625250e-01, 6.14006170e-03,\n",
       "         8.63271900e-03, 9.91339200e-02, 5.05607700e-02, 5.10902840e-03],\n",
       "        [3.15274410e-03, 7.75418360e-02, 6.04169480e-02, 2.32631080e-03,\n",
       "         3.40822400e-04, 3.69073450e-03, 7.56110600e-02, 6.43980500e-03,\n",
       "         3.04176450e-02, 0.00000000e+00, 2.37536710e-02, 8.66470600e-03,\n",
       "         6.44413700e-02, 1.24200870e-02, 2.10712430e-03, 3.82928600e-02],\n",
       "        [1.33023890e-01, 9.97498900e-02, 6.87585600e-02, 3.61228000e-03,\n",
       "         1.94293770e-04, 4.36083450e-02, 1.07129030e-02, 3.79848600e-03,\n",
       "         4.43179230e-02, 7.98739400e-02, 3.91007700e-02, 8.54496500e-03,\n",
       "         1.82055900e-01, 1.08799220e-01, 1.17099130e-01, 2.59435300e-02],\n",
       "        [7.34597150e-02, 0.00000000e+00, 1.02658354e-01, 7.79101000e-02,\n",
       "         8.90371200e-02, 6.95996600e-02, 7.93373200e-04, 6.98004440e-02,\n",
       "         1.51099160e-01, 4.38241550e-02, 6.14771360e-02, 6.07092860e-02,\n",
       "         4.58426900e-02, 2.17615160e-02, 8.14751900e-02, 5.30901550e-02],\n",
       "        [8.08288400e-03, 4.41095100e-03, 0.00000000e+00, 3.61083040e-02,\n",
       "         1.29553720e-01, 7.17210900e-02, 2.19696800e-02, 9.20232300e-02,\n",
       "         1.40638820e-03, 1.37123190e-03, 2.57413930e-02, 1.37173500e-01,\n",
       "         3.04978530e-02, 6.40358700e-02, 5.44417280e-02, 0.00000000e+00],\n",
       "        [8.11420200e-02, 1.02652710e-03, 7.54727500e-02, 5.87313060e-02,\n",
       "         1.11995945e-02, 0.00000000e+00, 7.47721500e-04, 1.31309720e-03,\n",
       "         0.00000000e+00, 2.83051730e-02, 9.56163260e-02, 1.33010800e-03,\n",
       "         2.16996580e-02, 6.93637000e-03, 5.43703460e-03, 6.95580800e-03],\n",
       "        [1.88613650e-02, 7.46181160e-02, 1.62856950e-02, 1.20804660e-02,\n",
       "         0.00000000e+00, 7.82439100e-02, 6.14181940e-02, 0.00000000e+00,\n",
       "         4.89285770e-02, 3.42834780e-02, 6.84302600e-02, 2.30790540e-02,\n",
       "         5.58224000e-03, 4.26366960e-02, 2.01206520e-02, 9.58423500e-03],\n",
       "        [1.38651090e-01, 2.18961300e-03, 0.00000000e+00, 4.30028400e-02,\n",
       "         1.09940640e-01, 6.55766700e-02, 2.58170480e-02, 4.20969600e-02,\n",
       "         2.57275680e-02, 1.32345530e-01, 8.00668000e-02, 4.43763170e-02,\n",
       "         1.43562300e-01, 5.75335200e-02, 9.86947300e-02, 8.82917500e-02],\n",
       "        [3.86199470e-02, 1.82295740e-03, 0.00000000e+00, 4.16750570e-02,\n",
       "         0.00000000e+00, 1.04274900e-02, 8.60589100e-02, 6.89249800e-03,\n",
       "         4.27038800e-03, 1.93963540e-01, 2.36403030e-03, 4.78327700e-04,\n",
       "         2.04356930e-02, 7.71022660e-02, 6.19879500e-02, 1.92343130e-02],\n",
       "        [2.54365860e-02, 6.86774200e-02, 3.43603020e-04, 3.87754800e-03,\n",
       "         0.00000000e+00, 9.23311700e-03, 1.13894390e-01, 1.51678860e-01,\n",
       "         0.00000000e+00, 1.12163890e-01, 1.28923490e-02, 1.27558350e-01,\n",
       "         6.80328440e-03, 2.08152300e-04, 4.82773200e-02, 2.08307260e-02]],\n",
       "\n",
       "       [[1.34023280e-01, 4.28045880e-02, 3.16186030e-02, 1.98519340e-02,\n",
       "         1.24855160e-02, 1.89833060e-01, 7.68980160e-02, 3.54897640e-02,\n",
       "         4.86674000e-02, 0.00000000e+00, 5.69688900e-02, 3.86378940e-03,\n",
       "         1.46777390e-02, 3.43554500e-02, 2.10268700e-02, 0.00000000e+00],\n",
       "        [6.61607700e-03, 6.94383760e-02, 8.40208000e-02, 1.95497310e-02,\n",
       "         8.15775250e-02, 3.99357270e-02, 9.84928200e-02, 4.23766500e-03,\n",
       "         7.77249260e-02, 2.63293330e-02, 8.44100640e-02, 1.09731495e-01,\n",
       "         2.43571660e-02, 3.13590540e-02, 1.02204230e-02, 0.00000000e+00],\n",
       "        [8.24172000e-03, 1.11906370e-02, 0.00000000e+00, 5.61233470e-03,\n",
       "         2.01135170e-02, 6.07107580e-02, 1.05293420e-01, 4.58838980e-02,\n",
       "         5.56083470e-02, 4.54155650e-02, 3.54123900e-02, 6.05829430e-02,\n",
       "         2.73474550e-02, 2.17629580e-02, 3.35171560e-02, 6.21963030e-02],\n",
       "        [1.17787960e-03, 1.27072960e-02, 4.66824400e-02, 4.66653300e-02,\n",
       "         1.12468265e-01, 0.00000000e+00, 1.71752830e-02, 2.37937810e-02,\n",
       "         5.41049060e-02, 9.27835100e-03, 6.91878500e-03, 2.00999680e-02,\n",
       "         7.04868100e-02, 3.43764550e-04, 8.84139300e-02, 8.42996200e-02],\n",
       "        [1.35817050e-01, 8.23800040e-02, 1.37332760e-02, 0.00000000e+00,\n",
       "         4.55426660e-03, 1.52818680e-02, 1.06157780e-03, 9.81019700e-02,\n",
       "         4.05846650e-02, 8.38397800e-02, 1.20421230e-03, 1.22191490e-01,\n",
       "         6.82898300e-02, 1.11235900e-02, 2.17885920e-02, 3.73820480e-02],\n",
       "        [7.30978300e-03, 2.09347740e-02, 2.54654230e-02, 1.80309940e-02,\n",
       "         1.11060050e-02, 9.38517500e-04, 7.75926050e-03, 1.18867690e-01,\n",
       "         1.59245790e-01, 1.51166440e-01, 8.91097100e-02, 1.31165430e-02,\n",
       "         7.89082800e-02, 2.55618450e-02, 8.98703500e-02, 5.60915430e-02],\n",
       "        [1.22481630e-03, 7.93697000e-02, 3.74526130e-03, 9.26308700e-04,\n",
       "         0.00000000e+00, 9.68904050e-03, 7.89469700e-03, 1.29236890e-02,\n",
       "         8.35222150e-02, 4.02754600e-02, 7.57648400e-02, 3.66810270e-03,\n",
       "         4.06867550e-03, 1.02914570e-01, 2.55256600e-02, 0.00000000e+00],\n",
       "        [0.00000000e+00, 5.00762280e-02, 3.32398700e-02, 5.56678600e-04,\n",
       "         0.00000000e+00, 7.59116600e-03, 6.77991100e-02, 1.16495390e-02,\n",
       "         2.23603710e-02, 0.00000000e+00, 1.92839240e-02, 1.84342540e-02,\n",
       "         7.26982360e-02, 3.64267380e-02, 2.36908600e-04, 3.88147120e-02],\n",
       "        [1.47494970e-01, 8.47064550e-02, 5.49158570e-02, 7.99033200e-03,\n",
       "         2.84088780e-03, 3.31951700e-02, 1.73291140e-02, 3.89196100e-03,\n",
       "         3.59417800e-02, 5.60138340e-02, 5.87590230e-02, 3.67099100e-02,\n",
       "         2.02079180e-01, 9.09017250e-02, 1.65147680e-01, 4.20596800e-02],\n",
       "        [1.03383390e-01, 0.00000000e+00, 8.32539950e-02, 5.79485220e-02,\n",
       "         6.28100300e-02, 6.42657100e-02, 1.61920380e-02, 4.40849140e-02,\n",
       "         1.82653740e-01, 2.62721680e-02, 6.37223900e-02, 4.49200160e-02,\n",
       "         2.60760650e-02, 3.99514470e-02, 4.68452050e-02, 1.18753925e-01],\n",
       "        [7.30612200e-04, 3.23204980e-03, 0.00000000e+00, 3.00564780e-02,\n",
       "         1.53466020e-01, 8.38597500e-02, 1.63795170e-02, 7.07196150e-02,\n",
       "         7.98640500e-03, 1.07284270e-02, 3.22414640e-02, 1.34246530e-01,\n",
       "         2.34341980e-02, 6.41760300e-02, 7.94757750e-02, 6.57023600e-03],\n",
       "        [6.03837370e-02, 1.15865710e-03, 1.18397830e-01, 5.07205430e-02,\n",
       "         2.34134590e-02, 0.00000000e+00, 1.51657870e-03, 2.56620310e-02,\n",
       "         0.00000000e+00, 4.71504330e-02, 1.44193490e-01, 0.00000000e+00,\n",
       "         4.87054700e-02, 6.91108360e-03, 2.60782400e-02, 1.33706050e-03],\n",
       "        [2.82566620e-02, 9.66965800e-02, 3.22977380e-02, 9.83916900e-03,\n",
       "         0.00000000e+00, 5.96475800e-02, 1.24854500e-01, 0.00000000e+00,\n",
       "         3.26898100e-02, 6.50332050e-02, 7.22554000e-02, 2.66895570e-02,\n",
       "         4.42632240e-03, 1.42865380e-02, 1.29468655e-02, 0.00000000e+00],\n",
       "        [1.02877760e-01, 0.00000000e+00, 0.00000000e+00, 4.69009400e-02,\n",
       "         9.82810900e-02, 7.96481500e-02, 3.48897600e-02, 2.54755400e-02,\n",
       "         1.68345070e-02, 1.25739900e-01, 7.61759800e-02, 7.02389850e-02,\n",
       "         1.38302420e-01, 3.97975780e-02, 7.23746700e-02, 9.33592100e-02],\n",
       "        [3.24921270e-02, 4.18072500e-03, 0.00000000e+00, 2.76325200e-02,\n",
       "         0.00000000e+00, 2.14274130e-02, 8.78189900e-02, 3.26842260e-02,\n",
       "         4.19192950e-03, 1.63733960e-01, 7.75395240e-03, 3.56633910e-03,\n",
       "         1.50601580e-02, 9.04636460e-02, 8.09547900e-02, 2.54181600e-02],\n",
       "        [3.94428200e-02, 1.69484470e-02, 8.73606900e-04, 5.74406800e-03,\n",
       "         0.00000000e+00, 6.32951970e-03, 8.51158100e-02, 1.32700400e-01,\n",
       "         0.00000000e+00, 1.39189270e-01, 5.23589630e-02, 1.50589290e-01,\n",
       "         9.56635400e-03, 0.00000000e+00, 3.66044340e-02, 5.49824950e-02]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "\n",
    "def create_pairs(x, digit_indices): # balance 하게 만들어주네???(가장 작은 class의 개수에 맞춰서)\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n",
    "    for d in range(num_classes):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, num_classes)\n",
    "            dn = (d + inc) % num_classes\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    input = Input(shape=input_shape)\n",
    "    x = input    \n",
    "    x = Conv2D(32, 3, padding='same', activation='relu', \n",
    "           input_shape=( 16, 16 , 1))(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Conv2D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Conv2D(256, 3, padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    #x = Dropout(0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    \n",
    "    return Model(input, x)\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "input_shape = (16,16, 1)\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "662/662 [==============================] - ETA: 0s - loss: 0.1863 - accuracy: 0.7575WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0039s vs `on_test_batch_end` time: 0.0242s). Check your callbacks.\n",
      "662/662 [==============================] - 26s 40ms/step - loss: 0.1863 - accuracy: 0.7575 - val_loss: 0.2560 - val_accuracy: 0.6597\n",
      "Epoch 2/50\n",
      "662/662 [==============================] - 26s 40ms/step - loss: 0.1560 - accuracy: 0.7950 - val_loss: 0.2485 - val_accuracy: 0.6762\n",
      "Epoch 3/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.1457 - accuracy: 0.8095 - val_loss: 0.2483 - val_accuracy: 0.6716\n",
      "Epoch 4/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.1380 - accuracy: 0.8211 - val_loss: 0.2524 - val_accuracy: 0.6817\n",
      "Epoch 5/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.1326 - accuracy: 0.8294 - val_loss: 0.2597 - val_accuracy: 0.6676\n",
      "Epoch 6/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.1276 - accuracy: 0.8372 - val_loss: 0.2455 - val_accuracy: 0.6864\n",
      "Epoch 7/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.1235 - accuracy: 0.8429 - val_loss: 0.2375 - val_accuracy: 0.7063\n",
      "Epoch 8/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.1197 - accuracy: 0.8491 - val_loss: 0.2505 - val_accuracy: 0.6815\n",
      "Epoch 9/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.1167 - accuracy: 0.8535 - val_loss: 0.2657 - val_accuracy: 0.6701\n",
      "Epoch 10/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.1142 - accuracy: 0.8583 - val_loss: 0.2458 - val_accuracy: 0.6893\n",
      "Epoch 11/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.1112 - accuracy: 0.8630 - val_loss: 0.2561 - val_accuracy: 0.6732\n",
      "Epoch 12/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.1091 - accuracy: 0.8661 - val_loss: 0.2507 - val_accuracy: 0.6841\n",
      "Epoch 13/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.1067 - accuracy: 0.8699 - val_loss: 0.2545 - val_accuracy: 0.6732\n",
      "Epoch 14/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.1047 - accuracy: 0.8724 - val_loss: 0.2491 - val_accuracy: 0.6907\n",
      "Epoch 15/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.1028 - accuracy: 0.8760 - val_loss: 0.2429 - val_accuracy: 0.6960\n",
      "Epoch 16/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.1011 - accuracy: 0.8783 - val_loss: 0.2513 - val_accuracy: 0.6817\n",
      "Epoch 17/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0996 - accuracy: 0.8808 - val_loss: 0.2289 - val_accuracy: 0.7167\n",
      "Epoch 18/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0979 - accuracy: 0.8831 - val_loss: 0.2401 - val_accuracy: 0.6946\n",
      "Epoch 19/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0968 - accuracy: 0.8848 - val_loss: 0.2459 - val_accuracy: 0.6785\n",
      "Epoch 20/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0957 - accuracy: 0.8866 - val_loss: 0.2404 - val_accuracy: 0.6849\n",
      "Epoch 21/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0944 - accuracy: 0.8880 - val_loss: 0.2356 - val_accuracy: 0.7054\n",
      "Epoch 22/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0935 - accuracy: 0.8895 - val_loss: 0.2295 - val_accuracy: 0.7015\n",
      "Epoch 23/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0925 - accuracy: 0.8904 - val_loss: 0.2451 - val_accuracy: 0.6870\n",
      "Epoch 24/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0916 - accuracy: 0.8921 - val_loss: 0.2320 - val_accuracy: 0.7166\n",
      "Epoch 25/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0906 - accuracy: 0.8935 - val_loss: 0.2475 - val_accuracy: 0.6854\n",
      "Epoch 26/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0899 - accuracy: 0.8944 - val_loss: 0.2414 - val_accuracy: 0.7006\n",
      "Epoch 27/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0893 - accuracy: 0.8956 - val_loss: 0.2396 - val_accuracy: 0.7106\n",
      "Epoch 28/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0883 - accuracy: 0.8978 - val_loss: 0.2283 - val_accuracy: 0.7154\n",
      "Epoch 29/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0877 - accuracy: 0.8973 - val_loss: 0.2418 - val_accuracy: 0.6939\n",
      "Epoch 30/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0868 - accuracy: 0.8992 - val_loss: 0.2406 - val_accuracy: 0.6925\n",
      "Epoch 31/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0860 - accuracy: 0.8996 - val_loss: 0.2455 - val_accuracy: 0.6953\n",
      "Epoch 32/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0857 - accuracy: 0.9007 - val_loss: 0.2277 - val_accuracy: 0.7167\n",
      "Epoch 33/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0850 - accuracy: 0.9009 - val_loss: 0.2311 - val_accuracy: 0.7050\n",
      "Epoch 34/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0843 - accuracy: 0.9022 - val_loss: 0.2373 - val_accuracy: 0.6934\n",
      "Epoch 35/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0840 - accuracy: 0.9028 - val_loss: 0.2375 - val_accuracy: 0.7105\n",
      "Epoch 36/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0833 - accuracy: 0.9032 - val_loss: 0.2438 - val_accuracy: 0.6947\n",
      "Epoch 37/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0829 - accuracy: 0.9042 - val_loss: 0.2380 - val_accuracy: 0.7022\n",
      "Epoch 38/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0821 - accuracy: 0.9050 - val_loss: 0.2390 - val_accuracy: 0.6981\n",
      "Epoch 39/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0819 - accuracy: 0.9053 - val_loss: 0.2413 - val_accuracy: 0.7014\n",
      "Epoch 40/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0814 - accuracy: 0.9056 - val_loss: 0.2381 - val_accuracy: 0.6985\n",
      "Epoch 41/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0808 - accuracy: 0.9065 - val_loss: 0.2361 - val_accuracy: 0.7168\n",
      "Epoch 42/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0806 - accuracy: 0.9067 - val_loss: 0.2348 - val_accuracy: 0.7121\n",
      "Epoch 43/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0803 - accuracy: 0.9070 - val_loss: 0.2266 - val_accuracy: 0.7068\n",
      "Epoch 44/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0798 - accuracy: 0.9080 - val_loss: 0.2303 - val_accuracy: 0.7043\n",
      "Epoch 45/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0794 - accuracy: 0.9085 - val_loss: 0.2342 - val_accuracy: 0.7032\n",
      "Epoch 46/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0790 - accuracy: 0.9087 - val_loss: 0.2282 - val_accuracy: 0.7090\n",
      "Epoch 47/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0785 - accuracy: 0.9095 - val_loss: 0.2416 - val_accuracy: 0.6988\n",
      "Epoch 48/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0782 - accuracy: 0.9099 - val_loss: 0.2333 - val_accuracy: 0.7159\n",
      "Epoch 49/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0778 - accuracy: 0.9102 - val_loss: 0.2413 - val_accuracy: 0.6981\n",
      "Epoch 50/50\n",
      "662/662 [==============================] - 26s 39ms/step - loss: 0.0777 - accuracy: 0.9107 - val_loss: 0.2265 - val_accuracy: 0.7148\n",
      "* Accuracy on training set: 90.87%\n",
      "* Accuracy on test set: 72.10%\n"
     ]
    }
   ],
   "source": [
    "# network definition\n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance,\n",
    "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance) # input, output\n",
    "\n",
    "# train\n",
    "rms = RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
    "history = model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          batch_size=500,\n",
    "          epochs=epochs,\n",
    "          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n",
    "\n",
    "# compute final accuracy on training and test sets\n",
    "y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(tr_y, y_pred)\n",
    "y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(te_y, y_pred)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( 1*( y_pred.ravel() < 0.5 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2183,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( 1*( y_pred.ravel() < 0.5 ) ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2183,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{40648: array([0, 0, 1, 1, 0, 0, 0, 0, 0, 0]),\n",
       " 66052: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]),\n",
       " 37783: array([1, 1, 0, 0, 0]),\n",
       " 59761: array([0, 0, 0, 1, 1]),\n",
       " 16639: array([1, 1, 1, 1]),\n",
       " 17958: array([1, 1, 1, 1, 1]),\n",
       " 10918: array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 26542: array([1, 1, 1, 1]),\n",
       " 71651: array([0, 0, 0, 1, 1]),\n",
       " 45696: array([0, 1]),\n",
       " 4253: array([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]),\n",
       " 63461: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 572: array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]),\n",
       " 66460: array([0]),\n",
       " 70828: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0]),\n",
       " 34741: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 14588: array([1, 1, 1, 1, 1]),\n",
       " 8647: array([0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0]),\n",
       " 51675: array([0, 0, 0, 0, 1, 1, 1]),\n",
       " 44240: array([0, 0, 1, 1, 1]),\n",
       " 15772: array([1, 1, 1, 1, 0, 0, 0, 0]),\n",
       " 37766: array([0]),\n",
       " 39183: array([1, 1]),\n",
       " 67190: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]),\n",
       " 53857: array([0, 0, 0, 0, 0, 1, 1, 1]),\n",
       " 62549: array([1, 1]),\n",
       " 4438: array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0]),\n",
       " 71984: array([1, 1]),\n",
       " 18607: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 1, 0, 0, 0, 0, 0]),\n",
       " 29566: array([1, 1, 1]),\n",
       " 42329: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]),\n",
       " 41649: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "        0, 0, 0, 0, 0]),\n",
       " 57323: array([0, 1]),\n",
       " 35622: array([1, 1, 1, 1, 0, 0, 0, 0]),\n",
       " 19669: array([1, 1, 1, 1, 0, 0, 0, 0]),\n",
       " 54420: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 65907: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]),\n",
       " 6304: array([1]),\n",
       " 46173: array([1, 1, 1]),\n",
       " 32207: array([1, 1]),\n",
       " 68498: array([1]),\n",
       " 24879: array([1]),\n",
       " 26550: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0]),\n",
       " 6336: array([1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 673: array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 11706: array([1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 6168: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 63675: array([1, 1]),\n",
       " 45015: array([0, 0, 0, 0, 1, 1, 1]),\n",
       " 60: array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0]),\n",
       " 31880: array([0, 0, 0, 0, 1, 1, 1]),\n",
       " 9461: array([1, 1, 1, 1, 1, 0, 0]),\n",
       " 54931: array([0, 0, 0, 0, 0, 1, 1, 1]),\n",
       " 11074: array([1, 1, 1, 1, 1, 1, 1]),\n",
       " 25928: array([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]),\n",
       " 52850: array([1, 1]),\n",
       " 38244: array([1, 1, 1, 0, 0, 0, 0]),\n",
       " 14092: array([1, 1, 1, 1, 1, 1]),\n",
       " 29533: array([1, 1, 1, 1]),\n",
       " 72633: array([0, 0, 0, 0, 0, 0, 1, 1]),\n",
       " 19729: array([1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 63959: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 65697: array([1]),\n",
       " 63092: array([1, 1]),\n",
       " 12067: array([0, 1]),\n",
       " 9712: array([1, 1, 1, 1, 1, 1, 0, 0, 0, 0]),\n",
       " 35832: array([0, 0, 0, 0, 1, 1, 1]),\n",
       " 50058: array([1, 1, 1]),\n",
       " 8878: array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 10198: array([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]),\n",
       " 7132: array([1, 1, 1, 1, 1, 1, 1]),\n",
       " 19158: array([1, 1, 1, 1, 1, 1, 0, 0, 0]),\n",
       " 71760: array([1, 1]),\n",
       " 29882: array([1, 1, 1, 0, 0, 0, 0]),\n",
       " 2487: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1]),\n",
       " 45553: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]),\n",
       " 41970: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]),\n",
       " 37904: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 23021: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0]),\n",
       " 16687: array([1, 1, 1, 1, 1]),\n",
       " 20559: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 71620: array([0, 0, 0, 0, 0, 0, 0, 1]),\n",
       " 35756: array([1, 1, 1, 0, 0, 0, 0]),\n",
       " 65107: array([0]),\n",
       " 62058: array([0, 0, 0, 0, 1, 0, 0]),\n",
       " 68572: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 0, 0, 0]),\n",
       " 30575: array([1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 28196: array([1, 1, 1]),\n",
       " 44633: array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1]),\n",
       " 51809: array([1, 1, 1]),\n",
       " 62029: array([1]),\n",
       " 16289: array([1, 1, 1, 1]),\n",
       " 53259: array([0, 0, 0, 0, 1, 1, 1]),\n",
       " 33764: array([1, 1, 0, 0, 0]),\n",
       " 50154: array([1, 1, 1]),\n",
       " 9641: array([1, 1, 1, 1, 1, 1, 1]),\n",
       " 14665: array([1, 1, 1, 1, 1]),\n",
       " 63916: array([0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 47939: array([1]),\n",
       " 43573: array([1, 1, 1])}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.562553  ],\n",
       "       [1.5733085 ],\n",
       "       [0.18377545],\n",
       "       ...,\n",
       "       [0.16946608],\n",
       "       [0.04108986],\n",
       "       [0.14604653]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.562553  , 1.5733085 , 0.18377545, ..., 0.16946608, 0.04108986,\n",
       "       0.14604653], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('cnn_predicted', y_pred.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_predicted.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.load('cnn_predicted.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2183,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2183, 1)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( 1*( y_pred < 0.5 ) ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.562553  , 1.5733085 , 0.18377545, 0.46056923, 0.82140964],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.ravel()[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40648"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(y_test_dict.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( y_test_dict[40648] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40648\n",
      "0 10\n",
      "label_size : 2.0 prediction_size : 5\n",
      "0.4\n",
      "1.0\n",
      "\n",
      "\n",
      "66052\n",
      "10 17\n",
      "label_size : 2.0 prediction_size : 2\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "37783\n",
      "27 5\n",
      "label_size : 2.0 prediction_size : 3\n",
      "0.6666666666666666\n",
      "1.0\n",
      "\n",
      "\n",
      "59761\n",
      "32 5\n",
      "label_size : 2.0 prediction_size : 2\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "16639\n",
      "37 4\n",
      "label_size : 4.0 prediction_size : 4\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "17958\n",
      "41 5\n",
      "label_size : 5.0 prediction_size : 5\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "10918\n",
      "46 18\n",
      "label_size : 5.0 prediction_size : 15\n",
      "0.13333333333333333\n",
      "0.4\n",
      "\n",
      "\n",
      "26542\n",
      "64 4\n",
      "label_size : 4.0 prediction_size : 4\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "71651\n",
      "68 5\n",
      "label_size : 2.0 prediction_size : 2\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "45696\n",
      "73 2\n",
      "label_size : 1.0 prediction_size : 1\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "4253\n",
      "75 12\n",
      "label_size : 8.0 prediction_size : 8\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "63461\n",
      "87 96\n",
      "label_size : 2.0 prediction_size : 61\n",
      "0.03278688524590164\n",
      "1.0\n",
      "\n",
      "\n",
      "572\n",
      "183 17\n",
      "label_size : 14.0 prediction_size : 17\n",
      "0.8235294117647058\n",
      "1.0\n",
      "\n",
      "\n",
      "66460\n",
      "200 1\n",
      "label_size : 0.0 prediction_size : 0\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "\n",
      "70828\n",
      "201 24\n",
      "label_size : 1.0 prediction_size : 6\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "\n",
      "34741\n",
      "225 170\n",
      "label_size : 4.0 prediction_size : 35\n",
      "0.11428571428571428\n",
      "1.0\n",
      "\n",
      "\n",
      "14588\n",
      "395 5\n",
      "label_size : 5.0 prediction_size : 5\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "8647\n",
      "400 12\n",
      "label_size : 4.0 prediction_size : 6\n",
      "0.5\n",
      "0.75\n",
      "\n",
      "\n",
      "51675\n",
      "412 7\n",
      "label_size : 3.0 prediction_size : 6\n",
      "0.5\n",
      "1.0\n",
      "\n",
      "\n",
      "44240\n",
      "419 5\n",
      "label_size : 3.0 prediction_size : 3\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "15772\n",
      "424 8\n",
      "label_size : 4.0 prediction_size : 8\n",
      "0.5\n",
      "1.0\n",
      "\n",
      "\n",
      "37766\n",
      "432 1\n",
      "label_size : 0.0 prediction_size : 1\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "\n",
      "39183\n",
      "433 2\n",
      "label_size : 2.0 prediction_size : 2\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "67190\n",
      "435 11\n",
      "label_size : 2.0 prediction_size : 2\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "53857\n",
      "446 8\n",
      "label_size : 3.0 prediction_size : 3\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "62549\n",
      "454 2\n",
      "label_size : 2.0 prediction_size : 2\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "4438\n",
      "456 16\n",
      "label_size : 11.0 prediction_size : 11\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "71984\n",
      "472 2\n",
      "label_size : 2.0 prediction_size : 2\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "18607\n",
      "474 30\n",
      "label_size : 4.0 prediction_size : 4\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "29566\n",
      "504 3\n",
      "label_size : 3.0 prediction_size : 3\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "42329\n",
      "507 14\n",
      "label_size : 2.0 prediction_size : 14\n",
      "0.14285714285714285\n",
      "1.0\n",
      "\n",
      "\n",
      "41649\n",
      "521 27\n",
      "label_size : 3.0 prediction_size : 27\n",
      "0.1111111111111111\n",
      "1.0\n",
      "\n",
      "\n",
      "57323\n",
      "548 2\n",
      "label_size : 1.0 prediction_size : 1\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "\n",
      "35622\n",
      "550 8\n",
      "label_size : 4.0 prediction_size : 6\n",
      "0.6666666666666666\n",
      "1.0\n",
      "\n",
      "\n",
      "19669\n",
      "558 8\n",
      "label_size : 4.0 prediction_size : 4\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "54420\n",
      "566 52\n",
      "label_size : 3.0 prediction_size : 17\n",
      "0.17647058823529413\n",
      "1.0\n",
      "\n",
      "\n",
      "65907\n",
      "618 12\n",
      "label_size : 2.0 prediction_size : 2\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "6304\n",
      "630 1\n",
      "label_size : 1.0 prediction_size : 1\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "46173\n",
      "631 3\n",
      "label_size : 3.0 prediction_size : 3\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "32207\n",
      "634 2\n",
      "label_size : 2.0 prediction_size : 2\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "68498\n",
      "636 1\n",
      "label_size : 1.0 prediction_size : 0\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "\n",
      "24879\n",
      "637 1\n",
      "label_size : 1.0 prediction_size : 1\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "26550\n",
      "638 21\n",
      "label_size : 4.0 prediction_size : 5\n",
      "0.8\n",
      "1.0\n",
      "\n",
      "\n",
      "6336\n",
      "659 22\n",
      "label_size : 7.0 prediction_size : 19\n",
      "0.3684210526315789\n",
      "1.0\n",
      "\n",
      "\n",
      "673\n",
      "681 32\n",
      "label_size : 16.0 prediction_size : 14\n",
      "1.0\n",
      "0.875\n",
      "\n",
      "\n",
      "11706\n",
      "713 8\n",
      "label_size : 8.0 prediction_size : 8\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "6168\n",
      "721 519\n",
      "label_size : 7.0 prediction_size : 244\n",
      "0.028688524590163935\n",
      "1.0\n",
      "\n",
      "\n",
      "63675\n",
      "1240 2\n",
      "label_size : 2.0 prediction_size : 2\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "45015\n",
      "1242 7\n",
      "label_size : 3.0 prediction_size : 3\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "60\n",
      "1249 28\n",
      "label_size : 15.0 prediction_size : 21\n",
      "0.7142857142857143\n",
      "1.0\n",
      "\n",
      "\n",
      "31880\n",
      "1277 7\n",
      "label_size : 3.0 prediction_size : 3\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "9461\n",
      "1284 7\n",
      "label_size : 5.0 prediction_size : 6\n",
      "0.8333333333333334\n",
      "1.0\n",
      "\n",
      "\n",
      "54931\n",
      "1291 8\n",
      "label_size : 3.0 prediction_size : 3\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "11074\n",
      "1299 7\n",
      "label_size : 7.0 prediction_size : 7\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "25928\n",
      "1306 12\n",
      "label_size : 5.0 prediction_size : 5\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "52850\n",
      "1318 2\n",
      "label_size : 2.0 prediction_size : 2\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "38244\n",
      "1320 7\n",
      "label_size : 3.0 prediction_size : 3\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "14092\n",
      "1327 6\n",
      "label_size : 6.0 prediction_size : 6\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "29533\n",
      "1333 4\n",
      "label_size : 4.0 prediction_size : 4\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "72633\n",
      "1337 8\n",
      "label_size : 2.0 prediction_size : 2\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "19729\n",
      "1345 12\n",
      "label_size : 4.0 prediction_size : 8\n",
      "0.5\n",
      "1.0\n",
      "\n",
      "\n",
      "63959\n",
      "1357 84\n",
      "label_size : 2.0 prediction_size : 29\n",
      "0.06896551724137931\n",
      "1.0\n",
      "\n",
      "\n",
      "65697\n",
      "1441 1\n",
      "label_size : 1.0 prediction_size : 1\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "63092\n",
      "1442 2\n",
      "label_size : 2.0 prediction_size : 2\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "12067\n",
      "1444 2\n",
      "label_size : 1.0 prediction_size : 1\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "9712\n",
      "1446 10\n",
      "label_size : 6.0 prediction_size : 6\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "35832\n",
      "1456 7\n",
      "label_size : 3.0 prediction_size : 3\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "50058\n",
      "1463 3\n",
      "label_size : 3.0 prediction_size : 3\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "8878\n",
      "1466 10\n",
      "label_size : 1.0 prediction_size : 3\n",
      "0.3333333333333333\n",
      "1.0\n",
      "\n",
      "\n",
      "10198\n",
      "1476 12\n",
      "label_size : 8.0 prediction_size : 9\n",
      "0.8888888888888888\n",
      "1.0\n",
      "\n",
      "\n",
      "7132\n",
      "1488 7\n",
      "label_size : 7.0 prediction_size : 7\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "19158\n",
      "1495 9\n",
      "label_size : 6.0 prediction_size : 5\n",
      "1.0\n",
      "0.8333333333333334\n",
      "\n",
      "\n",
      "71760\n",
      "1504 2\n",
      "label_size : 2.0 prediction_size : 2\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "29882\n",
      "1506 7\n",
      "label_size : 3.0 prediction_size : 3\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "2487\n",
      "1513 25\n",
      "label_size : 12.0 prediction_size : 12\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "45553\n",
      "1538 11\n",
      "label_size : 2.0 prediction_size : 2\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "41970\n",
      "1549 18\n",
      "label_size : 2.0 prediction_size : 10\n",
      "0.2\n",
      "1.0\n",
      "\n",
      "\n",
      "37904\n",
      "1567 64\n",
      "label_size : 4.0 prediction_size : 4\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "23021\n",
      "1631 93\n",
      "label_size : 4.0 prediction_size : 21\n",
      "0.19047619047619047\n",
      "1.0\n",
      "\n",
      "\n",
      "16687\n",
      "1724 5\n",
      "label_size : 5.0 prediction_size : 5\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "20559\n",
      "1729 322\n",
      "label_size : 3.0 prediction_size : 77\n",
      "0.03896103896103896\n",
      "1.0\n",
      "\n",
      "\n",
      "71620\n",
      "2051 8\n",
      "label_size : 1.0 prediction_size : 6\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "\n",
      "35756\n",
      "2059 7\n",
      "label_size : 3.0 prediction_size : 3\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "65107\n",
      "2066 1\n",
      "label_size : 0.0 prediction_size : 0\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "\n",
      "62058\n",
      "2067 7\n",
      "label_size : 1.0 prediction_size : 2\n",
      "0.5\n",
      "1.0\n",
      "\n",
      "\n",
      "68572\n",
      "2074 29\n",
      "label_size : 2.0 prediction_size : 9\n",
      "0.2222222222222222\n",
      "1.0\n",
      "\n",
      "\n",
      "30575\n",
      "2103 19\n",
      "label_size : 5.0 prediction_size : 12\n",
      "0.25\n",
      "0.6\n",
      "\n",
      "\n",
      "28196\n",
      "2122 3\n",
      "label_size : 3.0 prediction_size : 3\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "44633\n",
      "2125 10\n",
      "label_size : 2.0 prediction_size : 2\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "51809\n",
      "2135 3\n",
      "label_size : 3.0 prediction_size : 3\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "62029\n",
      "2138 1\n",
      "label_size : 1.0 prediction_size : 1\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "16289\n",
      "2139 4\n",
      "label_size : 4.0 prediction_size : 4\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "53259\n",
      "2143 7\n",
      "label_size : 3.0 prediction_size : 3\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "33764\n",
      "2150 5\n",
      "label_size : 2.0 prediction_size : 2\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "50154\n",
      "2155 3\n",
      "label_size : 3.0 prediction_size : 3\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "9641\n",
      "2158 7\n",
      "label_size : 7.0 prediction_size : 7\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "14665\n",
      "2165 5\n",
      "label_size : 5.0 prediction_size : 5\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "63916\n",
      "2170 9\n",
      "label_size : 0.0 prediction_size : 3\n",
      "0.0\n",
      "0.0\n",
      "\n",
      "\n",
      "47939\n",
      "2179 1\n",
      "label_size : 1.0 prediction_size : 1\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n",
      "43573\n",
      "2180 3\n",
      "label_size : 3.0 prediction_size : 3\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "precision_100 = []\n",
    "recall_100 = []\n",
    "\n",
    "grp_pred_w_key = {}\n",
    "grp_label_w_key = {}\n",
    "\n",
    "test_label = te_y\n",
    "predicted = ( 1*( y_pred.ravel() < 0.5 ) ) # 초과를 봐야해 미만을 봐야해?\n",
    "\n",
    "#start test key\n",
    "start_test_key = list(y_test_dict.keys())[0]\n",
    "#init start index\n",
    "start_index = 0\n",
    "\n",
    "for test_key in y_test_dict.keys(): \n",
    "    print(test_key)\n",
    "    if test_key == start_test_key:\n",
    "        start_index = 0\n",
    "    \n",
    "    test_obj_grp_size = len( y_test_dict[test_key] )\n",
    "    grp_pred = predicted[start_index : start_index + test_obj_grp_size]\n",
    "    grp_label = test_label[start_index : start_index +test_obj_grp_size]\n",
    "    # 저장\n",
    "    grp_pred_w_key[test_key] = grp_pred\n",
    "    grp_label_w_key[test_key] = grp_label\n",
    "    ####\n",
    "    \n",
    "    print(start_index, test_obj_grp_size)\n",
    "    \n",
    "    start_index += test_obj_grp_size\n",
    "    \n",
    "    print('label_size : {}'.format(np.sum( grp_label )), \n",
    "          'prediction_size : {}'.format(np.sum( grp_pred )) )\n",
    "    \n",
    "    # calculate precision / recall\n",
    "    precision_ = metrics.precision_score( grp_label , grp_pred )\n",
    "    recall_ = metrics.recall_score( grp_label , grp_pred )\n",
    "    \n",
    "    # print\n",
    "    print( precision_ )\n",
    "    print( recall_ )\n",
    "    print('\\n')\n",
    "    \n",
    "    # append precision / recall\n",
    "    precision_100.append( precision_ )\n",
    "    recall_100.append( recall_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7470528333613038"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(precision_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9045833333333334"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(recall_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
